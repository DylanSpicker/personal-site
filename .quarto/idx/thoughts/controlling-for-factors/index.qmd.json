{"title":"When Should We Control For Factors?","markdown":{"yaml":{"title":"When Should We Control For Factors?","author":"Dylan Spicker","date":"2019-07-01","slug":[],"categories":["statistics","teaching","research"],"tags":["statistics","teaching","research"],"description":"We are often told to control for confounding factors, but when should we?","image":"control.jpg","output":{"blogdown::html_page":{"toc":false,"fig_width":6,"dev":"svg"}}},"headingText":"Conditioning for Causality","containsRefs":false,"markdown":"\n## Simpson's Paradox\nThere is a well known statistical *\"paradox\"* [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox), which discusses the ability for a trend observed in your data to reverse when groups of interest are aggregated. The basic idea is often illustrated with the **UC Berkeley Gender Bias** example. If you took a look at the admissions data for 1973, you would note that 44% of men who applied, and only 35% of women, were accepted into their respective programs. However, four of the six departments at the school, women were accepted at higher rates than men. The issue is that, on the whole, women were applying to more competitive departments (such as English), where mentended to apply to less competitive disciplines (Engineering and Chemistry). This creates a scenario where there is no explicit discrimination at any department level, but it appears as though there is when aggregated.\n\nThe lesson from the above, statistically, tends to be **condition on relevant quantities**. That is, when we are conducting statistical analysis, we ought to \"control for\" the effects of possibly influential variables; if the above analysis had initially looked at acceptance rates **controlling for department of application**, a **more correct** conclusion would have been reached. Seems easy enough - so what is the issue?\n\n## Berkson's Paradox\n(Prepare for Deja Vu) There is a well known statistical *\"paradox\"* [Berkson's Paradox](https://en.wikipedia.org/wiki/Berkson%27s_paradox), which discusses the ability for a correlation observed in your data to reverse based on the set of individuals observed. The basic idea is often illustrated with [**Why Are Handsome Men Such Jerks?**](https://slate.com/human-interest/2014/06/berksons-fallacy-why-are-handsome-men-such-jerks.html) example. If you imagine scoring the handsomeness, and the niceness, of men numerically, then perhaps Jim will only date a guy who has some niceness plus handsomeness score that exceeds a threshold. We may say that, in the general population, nicer men also tend to be more handsome (who knows?) so that these two traits are positively correlated. However, among the men that Jim dates, he will observe that nicer men are on average less handsome (and vice-versa). Why? Well, if there is an exceedingly nice man, in order to cross the dating threshold for Jim, this guy does not need to be very handsome at all - and as such, there will be more observations that are extreme than would be expected in the general public.\n\nThe lesson from the above, statistically, tends to be **do not condition on irrelevant quantities**. That is, when we are conducting statistical analysis, we ought not \"control for\" the effects of irrelevant variables; if the above analysis had inititally looked at the pool of men that Jim dates, then we would erroneously conclude that handsomeness and niceness are negatively correlated. \n\n## Well, now what?\nWithout having a subject-matter understanding of the causal structure at play, it is not obvious as to whether a factor is a **confounder** (e.g. in the first example) or a **collider** (e.g. in the second example). Confounders should **always** be conditioned on in a causal analysis, where colliders should **never** be conditiond on. Doing this incorrectly will lead to incorrect conclusions regarding the presence of a causal effect. This ultimately means that we should **not** \"control for\" absolutely every, possible factor; it also ultimately means that we ought to \"control for\" every relevant factor. Because this cannot be empirically informed, causal inference necessitates importing assumptions from a subject matter expert.\n","srcMarkdownNoYaml":"\n# Conditioning for Causality\n## Simpson's Paradox\nThere is a well known statistical *\"paradox\"* [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox), which discusses the ability for a trend observed in your data to reverse when groups of interest are aggregated. The basic idea is often illustrated with the **UC Berkeley Gender Bias** example. If you took a look at the admissions data for 1973, you would note that 44% of men who applied, and only 35% of women, were accepted into their respective programs. However, four of the six departments at the school, women were accepted at higher rates than men. The issue is that, on the whole, women were applying to more competitive departments (such as English), where mentended to apply to less competitive disciplines (Engineering and Chemistry). This creates a scenario where there is no explicit discrimination at any department level, but it appears as though there is when aggregated.\n\nThe lesson from the above, statistically, tends to be **condition on relevant quantities**. That is, when we are conducting statistical analysis, we ought to \"control for\" the effects of possibly influential variables; if the above analysis had initially looked at acceptance rates **controlling for department of application**, a **more correct** conclusion would have been reached. Seems easy enough - so what is the issue?\n\n## Berkson's Paradox\n(Prepare for Deja Vu) There is a well known statistical *\"paradox\"* [Berkson's Paradox](https://en.wikipedia.org/wiki/Berkson%27s_paradox), which discusses the ability for a correlation observed in your data to reverse based on the set of individuals observed. The basic idea is often illustrated with [**Why Are Handsome Men Such Jerks?**](https://slate.com/human-interest/2014/06/berksons-fallacy-why-are-handsome-men-such-jerks.html) example. If you imagine scoring the handsomeness, and the niceness, of men numerically, then perhaps Jim will only date a guy who has some niceness plus handsomeness score that exceeds a threshold. We may say that, in the general population, nicer men also tend to be more handsome (who knows?) so that these two traits are positively correlated. However, among the men that Jim dates, he will observe that nicer men are on average less handsome (and vice-versa). Why? Well, if there is an exceedingly nice man, in order to cross the dating threshold for Jim, this guy does not need to be very handsome at all - and as such, there will be more observations that are extreme than would be expected in the general public.\n\nThe lesson from the above, statistically, tends to be **do not condition on irrelevant quantities**. That is, when we are conducting statistical analysis, we ought not \"control for\" the effects of irrelevant variables; if the above analysis had inititally looked at the pool of men that Jim dates, then we would erroneously conclude that handsomeness and niceness are negatively correlated. \n\n## Well, now what?\nWithout having a subject-matter understanding of the causal structure at play, it is not obvious as to whether a factor is a **confounder** (e.g. in the first example) or a **collider** (e.g. in the second example). Confounders should **always** be conditioned on in a causal analysis, where colliders should **never** be conditiond on. Doing this incorrectly will lead to incorrect conclusions regarding the presence of a causal effect. This ultimately means that we should **not** \"control for\" absolutely every, possible factor; it also ultimately means that we ought to \"control for\" every relevant factor. Because this cannot be empirically informed, causal inference necessitates importing assumptions from a subject matter expert.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":{"blogdown::html_page":{"toc":false,"fig_width":6,"dev":"svg"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"include-before-body":["../../header.html","../../blog_header.html"],"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","theme":"cosmo","page-layout":"article","title-block-banner":false,"title":"When Should We Control For Factors?","author":"Dylan Spicker","date":"2019-07-01","slug":[],"categories":["statistics","teaching","research"],"tags":["statistics","teaching","research"],"description":"We are often told to control for confounding factors, but when should we?","image":"control.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}